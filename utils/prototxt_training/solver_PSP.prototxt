#net: "/home/manish/tcs/arc_setup/utils/prototxt_training/resnet50_train.prototxt"
########path of training prototxt######################
net: ""


#learning rate policy
#    - fixed: always return base_lr.
#    - step: return base_lr * gamma ^ (floor(iter / step))
#    - exp: return base_lr * gamma ^ iter
#    - inv: return base_lr * (1 + gamma * iter) ^ (- power)
#    - multistep: similar to step but it allows non uniform steps defined by stepvalue
#    - poly: the effective learning rate follows a polynomial decay, to be zero by the max_iter.
#      return base_lr (1 - iter/max_iter) ^ (power)
#    - sigmoid: the effective learning rate follows a sigmod decay
#      return base_lr ( 1/(1 + exp(-gamma * (iter - stepsize))))

lr_policy: "step"
average_loss: 40
#base_lr: 1e-2
base_lr: 1e-3
stepsize: 50000
gamma: 0.1

#lr_policy: "poly"
#power: 0.9
#base_lr: 1e-1
momentum: 0.90
weight_decay: 0.0001

# mode
# CPU 0
# GPU 1
# type
# SGD = 0,
# NESTEROV = 1,
# ADAGRAD = 2,
# RMSPROP = 3,
# ADADELTA = 4,
# ADAM = 5

solver_mode: 1
solver_type: 1




iter_size: 1
max_iter: 150000
display: 1
snapshot: 1000


######## path of snapshot ##############
snapshot_prefix: "/home/manish/tcs/arc_setup/trained_models/final_"

